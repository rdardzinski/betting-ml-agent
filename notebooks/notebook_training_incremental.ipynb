# -*- coding: utf-8 -*-
"""
Notebook v3 – Multi-liga + Rolling Stats + Multi-market + JSON log
"""

import pandas as pd
import pickle
import json
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import os

# ===============================
# 1. LOAD HISTORY + NEW MATCHES
# ===============================

try:
    df_history = pd.read_csv("historical_data.csv")
except FileNotFoundError:
    df_history = pd.DataFrame()

# Free-first: pobranie nowych meczów z TheSportsDB
import requests

LEAGUES = {
    "EPL": 4328,
    "Bundesliga": 4331,
    "MLS": 4346
}

new_matches_list = []
for name, league_id in LEAGUES.items():
    url = f"https://www.thesportsdb.com/api/v1/json/3/eventsnextleague.php?id={league_id}"
    r = requests.get(url)
    if r.status_code != 200:
        continue
    data = r.json()
    if not data or not data.get("events"):
        continue
    for event in data["events"]:
        new_matches_list.append({
            "League": name,
            "HomeTeam": event["strHomeTeam"],
            "AwayTeam": event["strAwayTeam"],
            "Date": event["dateEvent"],
            "FTHG": 1,
            "FTAG": 1
        })

df_new = pd.DataFrame(new_matches_list)

# ===============================
# 2. Merge and deduplicate
# ===============================

df_history = pd.concat([df_history, df_new], ignore_index=True)
df_history.drop_duplicates(subset=["League","HomeTeam","AwayTeam","Date"], inplace=True)
df_history.to_csv("historical_data.csv", index=False)

# ===============================
# 3. Feature engineering
# ===============================

df_history["TotalGoals"] = df_history["FTHG"] + df_history["FTAG"]
df_history["Over25"] = (df_history["TotalGoals"] > 2.5).astype(int)
df_history["BTTS"] = ((df_history["FTHG"]>0) & (df_history["FTAG"]>0)).astype(int)
df_history = df_history.sort_values("Date")
df_history["HomeRollingGoals"] = df_history.groupby("HomeTeam")["FTHG"].rolling(5,min_periods=1).mean().reset_index(0,drop=True)
df_history["AwayRollingGoals"] = df_history.groupby("AwayTeam")["FTAG"].rolling(5,min_periods=1).mean().reset_index(0,drop=True)

# ===============================
# 4. Training – Multi-market
# ===============================

markets = ["Over25","BTTS"]
models = {}

for market in markets:
    X = df_history[["FTHG","FTAG","HomeRollingGoals","AwayRollingGoals"]]
    y = df_history[market]
    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)

    try:
        with open(f"agent_state_{market}.pkl","rb") as f:
            agent_state = pickle.load(f)
        model = agent_state["model"]
        model.n_estimators += 50
    except:
        model = RandomForestClassifier(n_estimators=200)

    model.fit(X_train,y_train)
    acc = model.score(X_test,y_test)
    print(f"{market} model accuracy:", acc)

    agent_state = {
        "model": model,
        "accuracy": acc
    }
    # ZAPIS W KATALOGU REPO
    with open(f"agent_state_{market}.pkl","wb") as f:
        pickle.dump(agent_state,f)

    models[market] = acc

# ===============================
# 5. Save metrics JSON
# ===============================

metrics = {
    "num_matches": len(df_history),
    "accuracies": models
}

with open("predictions_log.json","w") as f:
    json.dump(metrics,f)

print("Incremental retraining for multi-market done.")
